\graphicspath{{png/}}

\section{Описание}

\subsection*{Метод сопряженных градиентов}

Рассмотрим следующую задачу оптимизации: $F(x) = 1/2 * (Ax, x) - (b, x) -> inf, x \in R^n$. Здесь $A$ -- положительно определенная симметричная разреженная матрица размера $n \cdot n$. Заметим, что $F'(x) = Ax - b$ и условие $F'(x) = 0$ эквивалентно $Ax - b = 0$. Функция $F$ достигает своей нижней грани в единственной точке $x^*$, определяемой уравнением $Ax^* = b$.
\\ Будем говорить, что ненулевые векторы $p^{(0)}, p^{(1)}, \dots, p^{(m - 1)}$ называются {\it взаимно сопряженными} относительно матрицы $A$, если $(Ap^{(n)}, p^{(l)}) = 0$ для всех $n \neq l$.
\\ Под {\it методом сопряженных направлений} для минимизации квадратичной функции будем понимать метод
$$x^{(n + 1)} = x^{(n)} + \alpha_{n}p^{(n)} \tab (n = 0, 1, 2, \dots, m - 1),$$
в котором направления $p^{(0)}, p^{(1)}, \dots, p^{(m - 1)}$ взаимно сопряжены, а шаги
$$\alpha_{n} = \frac{(r^{(n)}, p^{(n)})}{(Ap^{(n)}, p^{(n)})},$$ где  $r^{(n)} = r^{(n-1)} - \alpha_nAp^{(n)}$ -- антиградиент, получаются как решение задач одномерной минимизации: 
$$\phi_n(\alpha_n) = min_{\alpha \geq 0} \phi_n(\alpha), \phi_n(\alpha) = F(x^{(n)}) + \alpha p^{(n)} $$
В методе сопряженных градиентов направления $p^{(n)}$ строят по правилу: 
$$p^{(0)} = r^{(0)}, p^{(n)} = r^{(n)} + \beta_{n-1}p^{(n-1)}, n \geq 1, $$ где $$\beta_{n-1} = \frac{(r^{(n)}, r^{(n)})}{(r^{(n-1)}, r^{(n-1)})} , а$$ $$r^{(n)} = r^{(n - 1)} - \alpha_{n-1}Ap^{(n - 1)} .$$
\subsection*{Анализ метода}
Для метода сопряжённых градиентов справедлива следующая теорема:
Теорема Пусть $F(x) = \frac{1}{2}  (Ax, x) - (b, x)$ ,  $A$где - симметричная положительно определённая матрица размера $n$. Тогда метод сопряжённых градиентов сходится не более чем за $n$ шагов. В компьютерном представлении, однако, существуют проблемы с представлением вещественных чисел, в связи с чем, количество итераций может превышать $n$. 
\subsection*{Сходимость} 
Более тонкий анализ показывает, что число итераций не превышает m, где m - число различных собственных значений матрицы A. Для оценки скорости сходимости верна следующая (довольно грубая) оценка:
 $$|| x_k - x_* ||_A \leq  ( \frac{ \sqrt  {\kappa(A) } - 1}{ \sqrt { \kappa(A) } + 1} ) || x_0 - x_* ||_A,$$ где
 $\kappa(A) = || A || \: || A^{-1} || = \lambda_1 / \lambda_n .$ Она позволяет оценить скорость сходимости, если известны оценки для максимального $\lambda_1$ и минимального $\lambda_n$ собственных значений матрицы A. На практике чаще всего используют следующий критерий останова: $$|| r_k || < \varepsilon. $$
\subsection*{Вычислительная сложность}
На каждой итерации метода выполняется $O(n^2)$ операций. Такое количество операций требуется для вычисления произведения $Ap^{(n)}$ - это самая трудоёмкая процедура на каждой итерации. Отальные вычисления требуют $O(n)$ операций. Суммарная вычислительная сложность метода не превышает $O(n^3)$ - так как число итераций не больше $n$.

\pagebreak
